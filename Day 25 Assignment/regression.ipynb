{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0576d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_curve, \n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b60f711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_regression(\n",
    "    n_samples=7000,\n",
    "    n_features=20,\n",
    "    random_state=42\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20c6dd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67063669,  0.4271487 ,  1.2093476 , ...,  0.28787656,\n",
       "         0.89598888, -1.78850926],\n",
       "       [ 0.83693173, -1.02984504, -1.07989144, ...,  0.33488903,\n",
       "         2.47884606,  0.13977438],\n",
       "       [ 2.46602867, -1.41981334,  1.4017903 , ..., -0.29604111,\n",
       "        -0.74762643,  0.54474577],\n",
       "       ...,\n",
       "       [-0.69158518,  0.86697793,  0.74550101, ..., -0.67429478,\n",
       "        -1.16783583, -2.72672405],\n",
       "       [ 0.8705648 , -0.67488528, -0.25593266, ..., -0.60294406,\n",
       "        -0.64955479, -1.03990373],\n",
       "       [-0.14857758, -0.87888457, -0.33007573, ...,  1.04610502,\n",
       "        -1.95956849,  0.8586596 ]], shape=(7000, 20))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15973dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 229.23057338,  -58.62777649, -147.7418074 , ..., -175.33277445,\n",
       "         24.62701819,  -10.86099019], shape=(7000,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b4c379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e408c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229.230573</th>\n",
       "      <td>0.670637</td>\n",
       "      <td>0.427149</td>\n",
       "      <td>1.209348</td>\n",
       "      <td>2.308310</td>\n",
       "      <td>-0.145141</td>\n",
       "      <td>-0.533234</td>\n",
       "      <td>2.179278</td>\n",
       "      <td>-1.275279</td>\n",
       "      <td>1.645286</td>\n",
       "      <td>-0.369332</td>\n",
       "      <td>-0.713004</td>\n",
       "      <td>0.443426</td>\n",
       "      <td>-0.663032</td>\n",
       "      <td>0.117497</td>\n",
       "      <td>-0.331665</td>\n",
       "      <td>-1.214266</td>\n",
       "      <td>-0.263520</td>\n",
       "      <td>0.287877</td>\n",
       "      <td>0.895989</td>\n",
       "      <td>-1.788509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-58.627776</th>\n",
       "      <td>0.836932</td>\n",
       "      <td>-1.029845</td>\n",
       "      <td>-1.079891</td>\n",
       "      <td>-0.882279</td>\n",
       "      <td>-0.378978</td>\n",
       "      <td>0.339065</td>\n",
       "      <td>-0.659528</td>\n",
       "      <td>-0.237544</td>\n",
       "      <td>-0.898627</td>\n",
       "      <td>-0.983312</td>\n",
       "      <td>0.987778</td>\n",
       "      <td>0.976441</td>\n",
       "      <td>2.233241</td>\n",
       "      <td>-0.323143</td>\n",
       "      <td>-0.334261</td>\n",
       "      <td>-0.459676</td>\n",
       "      <td>-0.591078</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>2.478846</td>\n",
       "      <td>0.139774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-147.741807</th>\n",
       "      <td>2.466029</td>\n",
       "      <td>-1.419813</td>\n",
       "      <td>1.401790</td>\n",
       "      <td>0.631748</td>\n",
       "      <td>-0.403445</td>\n",
       "      <td>-0.745681</td>\n",
       "      <td>1.109442</td>\n",
       "      <td>1.317837</td>\n",
       "      <td>0.221972</td>\n",
       "      <td>-1.313572</td>\n",
       "      <td>-0.584378</td>\n",
       "      <td>-0.632567</td>\n",
       "      <td>2.265215</td>\n",
       "      <td>1.305968</td>\n",
       "      <td>-0.924405</td>\n",
       "      <td>1.310082</td>\n",
       "      <td>0.013486</td>\n",
       "      <td>-0.296041</td>\n",
       "      <td>-0.747626</td>\n",
       "      <td>0.544746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-48.413366</th>\n",
       "      <td>0.938561</td>\n",
       "      <td>-1.981640</td>\n",
       "      <td>0.480224</td>\n",
       "      <td>1.680003</td>\n",
       "      <td>-0.580651</td>\n",
       "      <td>-1.678166</td>\n",
       "      <td>-0.816508</td>\n",
       "      <td>1.084048</td>\n",
       "      <td>-0.647885</td>\n",
       "      <td>-1.630966</td>\n",
       "      <td>-0.326729</td>\n",
       "      <td>-2.615347</td>\n",
       "      <td>0.427371</td>\n",
       "      <td>1.279275</td>\n",
       "      <td>1.064417</td>\n",
       "      <td>-0.642443</td>\n",
       "      <td>-1.619538</td>\n",
       "      <td>-1.190152</td>\n",
       "      <td>-0.048913</td>\n",
       "      <td>0.208870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.635109</th>\n",
       "      <td>1.774063</td>\n",
       "      <td>0.562897</td>\n",
       "      <td>1.041018</td>\n",
       "      <td>0.652780</td>\n",
       "      <td>0.146791</td>\n",
       "      <td>-1.960234</td>\n",
       "      <td>0.914889</td>\n",
       "      <td>-1.509788</td>\n",
       "      <td>0.341102</td>\n",
       "      <td>-1.277914</td>\n",
       "      <td>0.415903</td>\n",
       "      <td>-0.457292</td>\n",
       "      <td>-0.976299</td>\n",
       "      <td>-0.400945</td>\n",
       "      <td>-0.186220</td>\n",
       "      <td>-0.781870</td>\n",
       "      <td>0.315335</td>\n",
       "      <td>-0.491555</td>\n",
       "      <td>0.418040</td>\n",
       "      <td>0.078838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282.102704</th>\n",
       "      <td>0.562881</td>\n",
       "      <td>-0.505747</td>\n",
       "      <td>0.342338</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>-0.335138</td>\n",
       "      <td>1.685014</td>\n",
       "      <td>-0.485306</td>\n",
       "      <td>1.554160</td>\n",
       "      <td>-1.058908</td>\n",
       "      <td>1.481663</td>\n",
       "      <td>-0.742484</td>\n",
       "      <td>1.987061</td>\n",
       "      <td>1.230875</td>\n",
       "      <td>0.853976</td>\n",
       "      <td>1.962587</td>\n",
       "      <td>1.341476</td>\n",
       "      <td>-0.879814</td>\n",
       "      <td>-0.530971</td>\n",
       "      <td>1.011463</td>\n",
       "      <td>1.954157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-158.390303</th>\n",
       "      <td>1.191928</td>\n",
       "      <td>0.791071</td>\n",
       "      <td>-1.061690</td>\n",
       "      <td>-1.389883</td>\n",
       "      <td>-0.906632</td>\n",
       "      <td>2.306313</td>\n",
       "      <td>-0.662857</td>\n",
       "      <td>-0.567911</td>\n",
       "      <td>0.982113</td>\n",
       "      <td>-1.178472</td>\n",
       "      <td>-0.278716</td>\n",
       "      <td>0.320068</td>\n",
       "      <td>-0.335302</td>\n",
       "      <td>-0.953780</td>\n",
       "      <td>-0.633348</td>\n",
       "      <td>0.884338</td>\n",
       "      <td>0.730997</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>0.201264</td>\n",
       "      <td>-0.145768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-175.332774</th>\n",
       "      <td>-0.691585</td>\n",
       "      <td>0.866978</td>\n",
       "      <td>0.745501</td>\n",
       "      <td>-0.708498</td>\n",
       "      <td>0.279252</td>\n",
       "      <td>2.540103</td>\n",
       "      <td>1.133136</td>\n",
       "      <td>2.308835</td>\n",
       "      <td>1.260212</td>\n",
       "      <td>0.127366</td>\n",
       "      <td>0.137436</td>\n",
       "      <td>-0.015867</td>\n",
       "      <td>1.404809</td>\n",
       "      <td>0.630090</td>\n",
       "      <td>-1.809583</td>\n",
       "      <td>0.054678</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>-0.674295</td>\n",
       "      <td>-1.167836</td>\n",
       "      <td>-2.726724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.627018</th>\n",
       "      <td>0.870565</td>\n",
       "      <td>-0.674885</td>\n",
       "      <td>-0.255933</td>\n",
       "      <td>0.882957</td>\n",
       "      <td>0.153039</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>1.346578</td>\n",
       "      <td>1.060252</td>\n",
       "      <td>0.886709</td>\n",
       "      <td>0.425384</td>\n",
       "      <td>1.002554</td>\n",
       "      <td>-0.195464</td>\n",
       "      <td>-0.497561</td>\n",
       "      <td>1.090748</td>\n",
       "      <td>-0.388416</td>\n",
       "      <td>-0.853501</td>\n",
       "      <td>0.138519</td>\n",
       "      <td>-0.602944</td>\n",
       "      <td>-0.649555</td>\n",
       "      <td>-1.039904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-10.860990</th>\n",
       "      <td>-0.148578</td>\n",
       "      <td>-0.878885</td>\n",
       "      <td>-0.330076</td>\n",
       "      <td>1.823714</td>\n",
       "      <td>1.406280</td>\n",
       "      <td>-0.729438</td>\n",
       "      <td>2.943648</td>\n",
       "      <td>-0.807525</td>\n",
       "      <td>0.126844</td>\n",
       "      <td>-1.386519</td>\n",
       "      <td>0.836936</td>\n",
       "      <td>0.805132</td>\n",
       "      <td>0.588065</td>\n",
       "      <td>1.494966</td>\n",
       "      <td>0.440383</td>\n",
       "      <td>-0.727386</td>\n",
       "      <td>-1.226853</td>\n",
       "      <td>1.046105</td>\n",
       "      <td>-1.959568</td>\n",
       "      <td>0.858660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5   \\\n",
       " 229.230573  0.670637  0.427149  1.209348  2.308310 -0.145141 -0.533234   \n",
       "-58.627776   0.836932 -1.029845 -1.079891 -0.882279 -0.378978  0.339065   \n",
       "-147.741807  2.466029 -1.419813  1.401790  0.631748 -0.403445 -0.745681   \n",
       "-48.413366   0.938561 -1.981640  0.480224  1.680003 -0.580651 -1.678166   \n",
       " 18.635109   1.774063  0.562897  1.041018  0.652780  0.146791 -1.960234   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       " 282.102704  0.562881 -0.505747  0.342338  0.003696 -0.335138  1.685014   \n",
       "-158.390303  1.191928  0.791071 -1.061690 -1.389883 -0.906632  2.306313   \n",
       "-175.332774 -0.691585  0.866978  0.745501 -0.708498  0.279252  2.540103   \n",
       " 24.627018   0.870565 -0.674885 -0.255933  0.882957  0.153039  0.726935   \n",
       "-10.860990  -0.148578 -0.878885 -0.330076  1.823714  1.406280 -0.729438   \n",
       "\n",
       "                   6         7         8         9         10        11  \\\n",
       " 229.230573  2.179278 -1.275279  1.645286 -0.369332 -0.713004  0.443426   \n",
       "-58.627776  -0.659528 -0.237544 -0.898627 -0.983312  0.987778  0.976441   \n",
       "-147.741807  1.109442  1.317837  0.221972 -1.313572 -0.584378 -0.632567   \n",
       "-48.413366  -0.816508  1.084048 -0.647885 -1.630966 -0.326729 -2.615347   \n",
       " 18.635109   0.914889 -1.509788  0.341102 -1.277914  0.415903 -0.457292   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       " 282.102704 -0.485306  1.554160 -1.058908  1.481663 -0.742484  1.987061   \n",
       "-158.390303 -0.662857 -0.567911  0.982113 -1.178472 -0.278716  0.320068   \n",
       "-175.332774  1.133136  2.308835  1.260212  0.127366  0.137436 -0.015867   \n",
       " 24.627018   1.346578  1.060252  0.886709  0.425384  1.002554 -0.195464   \n",
       "-10.860990   2.943648 -0.807525  0.126844 -1.386519  0.836936  0.805132   \n",
       "\n",
       "                   12        13        14        15        16        17  \\\n",
       " 229.230573 -0.663032  0.117497 -0.331665 -1.214266 -0.263520  0.287877   \n",
       "-58.627776   2.233241 -0.323143 -0.334261 -0.459676 -0.591078  0.334889   \n",
       "-147.741807  2.265215  1.305968 -0.924405  1.310082  0.013486 -0.296041   \n",
       "-48.413366   0.427371  1.279275  1.064417 -0.642443 -1.619538 -1.190152   \n",
       " 18.635109  -0.976299 -0.400945 -0.186220 -0.781870  0.315335 -0.491555   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       " 282.102704  1.230875  0.853976  1.962587  1.341476 -0.879814 -0.530971   \n",
       "-158.390303 -0.335302 -0.953780 -0.633348  0.884338  0.730997 -0.012741   \n",
       "-175.332774  1.404809  0.630090 -1.809583  0.054678  0.004298 -0.674295   \n",
       " 24.627018  -0.497561  1.090748 -0.388416 -0.853501  0.138519 -0.602944   \n",
       "-10.860990   0.588065  1.494966  0.440383 -0.727386 -1.226853  1.046105   \n",
       "\n",
       "                   18        19  \n",
       " 229.230573  0.895989 -1.788509  \n",
       "-58.627776   2.478846  0.139774  \n",
       "-147.741807 -0.747626  0.544746  \n",
       "-48.413366  -0.048913  0.208870  \n",
       " 18.635109   0.418040  0.078838  \n",
       "...               ...       ...  \n",
       " 282.102704  1.011463  1.954157  \n",
       "-158.390303  0.201264 -0.145768  \n",
       "-175.332774 -1.167836 -2.726724  \n",
       " 24.627018  -0.649555 -1.039904  \n",
       "-10.860990  -1.959568  0.858660  \n",
       "\n",
       "[7000 rows x 20 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cff05c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_reg(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # param_grid = {\n",
    "    #         'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    #         'splitter': ['best', 'random'],\n",
    "    #         'max_depth': range(1, 11),\n",
    "    #         'max_features': ['sqrt', 'log2']\n",
    "    #     }\n",
    "    # model = DecisionTreeRegressor(random_state=42)\n",
    "    # cv = GridSearchCV(model,param_grid=param_grid,cv=5,scoring='accuracy')\n",
    "    # cv.fit(X_train, y_train)\n",
    "    best_model = DecisionTreeRegressor()\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "    cc = classification_report(y_test, y_pred)\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = ['Not Churn','Churn'])\n",
    "\n",
    "    return {\n",
    "                print(\"Model: \", best_model),\n",
    "                print(\"Score of Model\" ,acc*100),\n",
    "                print(\"Confusion Matrix:\", cm),\n",
    "                print(\"AUC Score: \", auc_score*100),\n",
    "                print(\"Classification Report:\",cc),\n",
    "                display.plot(),\n",
    "                plt.title(\"Confusion Matrix for the Decision tree\"),\n",
    "                plt.tight_layout(),\n",
    "                plt.show()\n",
    "    }\n",
    "\n",
    "    # plt.figure(figsize=(18, 10))\n",
    "    # tree.plot_tree(best_model,filled=True,feature_names=X.columns,class_names=True)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a684787",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdecision_tree_reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mdecision_tree_reg\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     13\u001b[39m best_model.fit(X_train, y_train)\n\u001b[32m     14\u001b[39m y_pred = best_model.predict(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m acc = \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m cm = confusion_matrix(y_test, y_pred)\n\u001b[32m     17\u001b[39m auc_score = roc_auc_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\metrics\\_classification.py:411\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[32m    410\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m y_type, y_true, y_pred, sample_weight = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    416\u001b[39m     differing_labels = _count_nonzero(y_true - y_pred, xp=xp, device=device, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\metrics\\_classification.py:138\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmultilabel-indicator\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "decision_tree_reg(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a27041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
